{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Generating NEST Data </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Modified: By Daniel Baur on 7th November 2019\n",
    "\n",
    "With this simple jupyter notebook you can determine the average number of primary quanta for a given event in a LXe TPC (interaction type, drift field, energy deposition, sample size) utilizing NEST. You need to have NEST installed on your local machine. Just type in your input into the chapter 1 cells (comments tell you what to do).\n",
    "\n",
    "What it cannot do:\n",
    "- spectra processing (You need a MC processor for such things. Maybe take a look at Signal Formation or ask the DARWIN MC team (i.e. Yanina).)\n",
    "- include detector properties (The primary quanta are independent from detector properties, e.g. lce, qe, ce, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0. **[Stuff](#0.-Stuff)**<br>\n",
    "    0.1 [Imports](#0.1-Imports)<br>\n",
    "    0.2 [Definitions](#0.2-Definitions)\n",
    "\n",
    "\n",
    "1. **[User Input](#1.-User-Input)**<br>\n",
    "\n",
    "\n",
    "2. **[Quanta Generation with NEST](#2.-Quanta-Generation-with-NEST)**<br>\n",
    "\n",
    "\n",
    "3. **[Postprocessing](#3.-Postprocessing)**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import pymongo\n",
    "#from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.special import binom as binomcoeff\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import quad\n",
    "import datetime\n",
    "import pprint\n",
    "import math\n",
    "import os\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to return datestring (e.g.: 20190714)\n",
    "def datestring():\n",
    "    return str(datetime.datetime.today().year) + str(datetime.datetime.today().month).zfill(2) + str(datetime.datetime.today().day).zfill(2)\n",
    "\n",
    "\n",
    "\n",
    "# function to return timestring (e.g.: 1725 for 17:25h)\n",
    "def timestring():\n",
    "    return str(datetime.datetime.now().time().hour).zfill(2) + str(datetime.datetime.now().time().minute).zfill(2)\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION:\n",
    "#   - read in the data from the text file generated with NEST\n",
    "#   - delete the file initially generated with NEST\n",
    "#   - write the NEST data file in a new text file (.txt) (along with the interaction type which is a priori not included in the NEST output file)\n",
    "#   - return the NEST data in the form of a list tuple which can then be saved as a np.array (.npy)\n",
    "# INPUT:\n",
    "#   - interaction_type (string): either \"ER\" or \"NR\", will be appended to each line of the output .txt file\n",
    "#   - begstring (string): name of the initially generated NEST output file\n",
    "#   - endstring (string): final name of the modified .txt output file\n",
    "#   - pathstring (string): path in which the initially generated NEST output file is stored\n",
    "# OUTPUT:\n",
    "#   - nest_output_tuple_list (list): contains the NEST data in the form of a tuple list (i.e. [(1,2,3), (1,2,3), ...])\n",
    "def format_NEST_output_txt_file(interaction_type, begstring, endstring, pathstring):\n",
    "    \n",
    "    ### extracting NEST data from the initially created NEST file\n",
    "    # creating the list the NEST output from NEST_output.txt is saved to, containing interaction_type, E_dep, E_drift, N_ph, N_e\n",
    "    NEST_output_list = []\n",
    "    # looping over the \"NEST_output.txt\" file and writing the contents into the upper list\n",
    "    NEST_output_unmodified_file = open(pathstring +begstring)\n",
    "    for line in NEST_output_unmodified_file:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        if len(row)!=12:\n",
    "            continue\n",
    "        elif \"E_[keV]\" in row[0]:\n",
    "            continue\n",
    "        elif \"g1\" in row[0]:\n",
    "            continue\n",
    "        else:\n",
    "            #print(row)\n",
    "            NEST_output = [interaction_type, float(row[0]), float(row[1]),  int(row[4]),  int(row[5])]  # order of the NEST output per simulated event: [interaction_type, E [keV],  field [V/cm],  Nph,  Ne]\n",
    "            NEST_output_list.append(NEST_output)\n",
    "    NEST_output_unmodified_file.close()\n",
    "    \n",
    "    ### deleting the initially created NEST file\n",
    "    subprocess.call(\"rm \" +pathstring +begstring, shell=True)\n",
    "    \n",
    "    ### writing the NEST data to a beautifully formatted .txt. file\n",
    "    # creating the .txt file the NEST data is saved to\n",
    "    NEST_output_modified_file = open(pathstring +\"/\" +endstring +\".txt\", \"w+\")\n",
    "    # writing the relevant data of every single event to file\n",
    "    NEST_output_modified_file.write(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "    NEST_output_modified_file.write(\"type\\tE_dep [keV]\\t\\tE_drift [V/cm]\\tN_ph\\t\\tN_e\\n\")\n",
    "    NEST_output_modified_file.write(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "    for i in range(len(NEST_output_list)):\n",
    "        NEST_output_modified_file.write(\"{interaction_type}\\t\\t{energydeposition:.2f}\\t\\t\\t{fieldstrength:.2f}\\t\\t\\t{Nph}\\t\\t\\t{Ne}\\r\\n\".format(interaction_type=str(NEST_output_list[i][0]), energydeposition=(NEST_output_list[i][1]),  fieldstrength=(NEST_output_list[i][2]),  Nph=int(NEST_output_list[i][3]), Ne=int(NEST_output_list[i][4])))\n",
    "    NEST_output_modified_file.write(\"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\")\n",
    "    # closing the file\n",
    "    NEST_output_modified_file.close()\n",
    "    \n",
    "    ### returning the NEST data so it can be saved to a np.array later on\n",
    "    nest_output_tuple_list = []\n",
    "    for i in range(len(NEST_output_list)):\n",
    "        nest_output_tuple_list.append((NEST_output_list[i][0], NEST_output_list[i][1], NEST_output_list[i][2], NEST_output_list[i][3], NEST_output_list[i][4]))\n",
    "    return nest_output_tuple_list\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION:\n",
    "#   - convert the input tuple list into a np.array (.npy)\n",
    "#   - save the np.array into the specified folder\n",
    "# INPUT:\n",
    "#   - arrayname (string): name of the output np.array (.npy will be appended)\n",
    "#   - arraypath (string): path into which the array will be saved\n",
    "#   - arraytuplelist (list): tuple list that will be converted into a np.array\n",
    "# OUTPUT:\n",
    "#   none\n",
    "def nest_output_tuple_to_np_array(arrayname, arraypath, arraytuplelist):\n",
    "    store_dtype = np.dtype([\n",
    "        (\"interaction_type\", np.unicode_, 16),\n",
    "        (\"energy_deposition\", np.float64),\n",
    "        (\"field_strength\", np.float64),\n",
    "        (\"number_of_photons\", np.uint16),\n",
    "        (\"number_of_electrons\", np.uint16),\n",
    "    ])\n",
    "    nest_output_array = np.array(arraytuplelist, store_dtype)\n",
    "    np.save(arraypath +arrayname +\".npy\", nest_output_array)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# function to convert a run_list entry into a string (e.g. for saving the respective NEST run)\n",
    "def generate_string_from_run_list_entry(run_list_entry):\n",
    "    run_list_string = \"EVENTS_\" +str(run_list_entry[0]) +\"__INTERACTION_\" +str(run_list_entry[1]) +\"__ENERGY_\" +str(run_list_entry[2]).replace(\".\",\"_\") +\"__EDRIFT_\" +str(run_list_entry[3]).replace(\".\",\"_\") #+\".npy\"\n",
    "    return run_list_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Input specified below the list `run_list` will be generated. The `i-th` Element of the run list is again a sublist of the form\n",
    "- `run_list[i][0]` --->   number of events of the same kind (`int`)\n",
    "- `run_list[i][1]` --->   interaction type (`string`, either `\"ER\"` or `\"NR\"`)\n",
    "- `run_list[i][2]` --->   energy deposition in $\\mathrm{keV_{nr}}$ or $\\mathrm{keV_{ee}}$ respectively (`float`)\n",
    "- `run_list[i][3]` --->   electrical drift field strength in $\\mathrm{\\frac{V}{cm}}$ (`float`)<br>\n",
    "\n",
    "and its entries will be passed to NEST as arguments. Each of the processed run-sublists will then be saved as a np.array (.npy).<br>\n",
    "\n",
    "remark: The executable `testNEST` is executed via:<br>\n",
    "`$ ./testNEST numEvts type_interaction E_min[kev] E_max[keV] field_drift[V/cm] x,y,z-position[mm] {optional:seed}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = datestring() +\"__ER_gnampfinos_for_Daniel_and_Mariana_2\"\n",
    "output_string = \"./OUTPUT_Generating_NEST_Data/\" # <---- don't modify this line unless you really have to (default: output_string = \"./OUTPUT_Generating_NEST_Data/\")\n",
    "nestpath = \"/home/db1086/NEST/install/testNEST\" # <---- don't modify this line unless you really have to (default: nestpath = \"/home/db1086/NEST/install/testNEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_manual_input = False\n",
    "\n",
    "manual_run_list = [\n",
    "    #[<number_of_samples_per_energy(int)>, <interaction_type(string, \"ER\" or \"NR\")>, <energy_deposition_in_keV(float)>, <drift_field_strength>],\n",
    "    #[50, 9.3967, \"ER\", 500],\n",
    "    [1000, \"ER\", 2791.41, 500],\n",
    "    [50, \"NR\", 20.41, 300]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Range Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_parameter_range = True\n",
    "\n",
    "param__number_of_events_per_paramter_samples = [10000] # usually there should be just one entry in this list\n",
    "param__interaction_type = [\"ER\"] # usually there should be just one entry in this list\n",
    "param__energy_deposition = [9.0, 32.0, 41.0]\n",
    "param__e_drift = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quanta Generation with NEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_list = [\n",
      "     [10000, 'ER', 9.0, 50]\n",
      "     [10000, 'ER', 9.0, 100]\n",
      "     [10000, 'ER', 9.0, 150]\n",
      "     [10000, 'ER', 9.0, 200]\n",
      "     [10000, 'ER', 9.0, 250]\n",
      "     [10000, 'ER', 9.0, 300]\n",
      "     [10000, 'ER', 9.0, 350]\n",
      "     [10000, 'ER', 9.0, 400]\n",
      "     [10000, 'ER', 9.0, 450]\n",
      "     [10000, 'ER', 9.0, 500]\n",
      "     [10000, 'ER', 32.0, 50]\n",
      "     [10000, 'ER', 32.0, 100]\n",
      "     [10000, 'ER', 32.0, 150]\n",
      "     [10000, 'ER', 32.0, 200]\n",
      "     [10000, 'ER', 32.0, 250]\n",
      "     [10000, 'ER', 32.0, 300]\n",
      "     [10000, 'ER', 32.0, 350]\n",
      "     [10000, 'ER', 32.0, 400]\n",
      "     [10000, 'ER', 32.0, 450]\n",
      "     [10000, 'ER', 32.0, 500]\n",
      "     [10000, 'ER', 41.0, 50]\n",
      "     [10000, 'ER', 41.0, 100]\n",
      "     [10000, 'ER', 41.0, 150]\n",
      "     [10000, 'ER', 41.0, 200]\n",
      "     [10000, 'ER', 41.0, 250]\n",
      "     [10000, 'ER', 41.0, 300]\n",
      "     [10000, 'ER', 41.0, 350]\n",
      "     [10000, 'ER', 41.0, 400]\n",
      "     [10000, 'ER', 41.0, 450]\n",
      "     [10000, 'ER', 41.0, 500]\n",
      "    ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### run list\n",
    "# preparing the run list\n",
    "if flag_parameter_range == True and flag_manual_input == False:\n",
    "    run_list = []\n",
    "    for i in param__number_of_events_per_paramter_samples:\n",
    "        for j in param__interaction_type:\n",
    "            for k in param__energy_deposition:\n",
    "                for l in param__e_drift:\n",
    "                    run_list.append([i,j,k,l])\n",
    "elif flag_parameter_range == False and flag_manual_input == True:\n",
    "    run_list = manual_run_list\n",
    "elif (flag_parameter_range == True and flag_manual_input == True) or (flag_parameter_range == False and flag_manual_input == False):\n",
    "    run_list = []\n",
    "    print(\"Both flags (flag_parameter_range and flag_manual_input) are either True or False.\")\n",
    "    print(\"Make sure you have exactly one flag set to True in order to run the program correctly.\")\n",
    "else:\n",
    "    run_list = []\n",
    "    print(\"You have picked some strange values for both flags (flag_parameter_range and flag_manual_input).\")\n",
    "    print(\"They have to be boolean whereas exactly one has to be set to True for the program to work correctly.\")\n",
    "    print(\"You suck!\")\n",
    "# printing the run list\n",
    "print(\"run_list = [\")\n",
    "for i in run_list:\n",
    "    print(\"    \", i)\n",
    "print(\"    ]\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Run: 20191107__ER_gnampfinos_for_Daniel_and_Mariana_2\n",
      "\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_50  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_100  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_150  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_200  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_250  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_300  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_350  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_400  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_450  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_9_0__EDRIFT_500  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_50  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_100  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_150  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_200  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_250  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_300  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_350  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_400  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_450  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_32_0__EDRIFT_500  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_50  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_100  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_150  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_200  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_250  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_300  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_350  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_400  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_450  <--- was saved successfully (.txt and .npy).\n",
      "The NEST run --->  EVENTS_10000__INTERACTION_ER__ENERGY_41_0__EDRIFT_500  <--- was saved successfully (.txt and .npy).\n",
      "\n",
      "Finished Run: 20191107__ER_gnampfinos_for_Daniel_and_Mariana_2\n"
     ]
    }
   ],
   "source": [
    "### running NEST\n",
    "run_NEST = True\n",
    "if run_NEST == True:\n",
    "    print(\"Starting Run: {}\\n\".format(run_name))\n",
    "    subprocess.call(\"mkdir \" +output_string +run_name, shell=True)\n",
    "    for i in range(len(run_list)):\n",
    "        savestring = generate_string_from_run_list_entry(run_list_entry=run_list[i])\n",
    "        #savestring = \"EVENTS_\" +str(run_list[i][0]) +\"__INTERACTION_\" +str(run_list[i][1]) +\"__ENERGY_\" +str(run_list[i][2]).replace(\".\",\"_\") +\"__EDRIFT_\" +str(run_list[i][3]).replace(\".\",\"_\")\n",
    "        temporarystring = \"NEST_output.txt\"\n",
    "        # running nest\n",
    "        subprocess.call(nestpath +\" \" +str(run_list[i][0]) +\" \" +str(run_list[i][1]) +\" \" +str(run_list[i][2]) +\" \" +str(run_list[i][2]) +\" \" + str(run_list[i][3]) +\" \" +\"-1\" +\" >> \" +output_string +run_name +\"/\" +temporarystring, shell=True)\n",
    "        # saving the NEST output as .txt and .npy file\n",
    "        nest_output_tuple_list = format_NEST_output_txt_file(interaction_type=run_list[i][1], begstring=temporarystring, endstring=savestring, pathstring=output_string+run_name+\"/\")\n",
    "        nest_output_tuple_to_np_array(arrayname=savestring, arraypath=output_string+run_name+\"/\", arraytuplelist=nest_output_tuple_list)\n",
    "        print(\"The NEST run --->  {}  <--- was saved successfully (.txt and .npy).\".format(savestring))\n",
    "    print(\"\\nFinished Run: {}\".format(run_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Summarizing the NEST Output\n",
      "-----------------------------------------------------\n",
      "Scanning for .npy files:\n",
      "[10000, 'ER', 9.0, 50] ---> file found\n",
      "[10000, 'ER', 9.0, 100] ---> file found\n",
      "[10000, 'ER', 9.0, 150] ---> file found\n",
      "[10000, 'ER', 9.0, 200] ---> file found\n",
      "[10000, 'ER', 9.0, 250] ---> file found\n",
      "[10000, 'ER', 9.0, 300] ---> file found\n",
      "[10000, 'ER', 9.0, 350] ---> file found\n",
      "[10000, 'ER', 9.0, 400] ---> file found\n",
      "[10000, 'ER', 9.0, 450] ---> file found\n",
      "[10000, 'ER', 9.0, 500] ---> file found\n",
      "[10000, 'ER', 32.0, 50] ---> file found\n",
      "[10000, 'ER', 32.0, 100] ---> file found\n",
      "[10000, 'ER', 32.0, 150] ---> file found\n",
      "[10000, 'ER', 32.0, 200] ---> file found\n",
      "[10000, 'ER', 32.0, 250] ---> file found\n",
      "[10000, 'ER', 32.0, 300] ---> file found\n",
      "[10000, 'ER', 32.0, 350] ---> file found\n",
      "[10000, 'ER', 32.0, 400] ---> file found\n",
      "[10000, 'ER', 32.0, 450] ---> file found\n",
      "[10000, 'ER', 32.0, 500] ---> file found\n",
      "[10000, 'ER', 41.0, 50] ---> file found\n",
      "[10000, 'ER', 41.0, 100] ---> file found\n",
      "[10000, 'ER', 41.0, 150] ---> file found\n",
      "[10000, 'ER', 41.0, 200] ---> file found\n",
      "[10000, 'ER', 41.0, 250] ---> file found\n",
      "[10000, 'ER', 41.0, 300] ---> file found\n",
      "[10000, 'ER', 41.0, 350] ---> file found\n",
      "[10000, 'ER', 41.0, 400] ---> file found\n",
      "[10000, 'ER', 41.0, 450] ---> file found\n",
      "[10000, 'ER', 41.0, 500] ---> file found\n",
      "Finished scanning for .npy files:\n",
      "-----------------------------------------------------\n",
      "For all runs in 'run_list' a corresponding NEST output .npy file was found.\n",
      "20191107__ER_gnampfinos_for_Daniel_and_Mariana_2__SUMMARY.npy saved:\n",
      "('number_of_events', 'interaction_type', 'energy_deposition', 'field_strength', 'mean_number_of_photons', 'mean_number_of_electrons', 'photon_yield')\n",
      "[(10000, 'ER',  9.,  50.,  451,  205, 50.20428889)\n",
      " (10000, 'ER',  9., 100.,  422,  235, 46.939     )\n",
      " (10000, 'ER',  9., 150.,  402,  254, 44.77513333)\n",
      " (10000, 'ER',  9., 200.,  391,  266, 43.46102222)\n",
      " (10000, 'ER',  9., 250.,  381,  275, 42.42052222)\n",
      " (10000, 'ER',  9., 300.,  374,  283, 41.56537778)\n",
      " (10000, 'ER',  9., 350.,  367,  289, 40.82528889)\n",
      " (10000, 'ER',  9., 400.,  362,  294, 40.26192222)\n",
      " (10000, 'ER',  9., 450.,  357,  300, 39.70247778)\n",
      " (10000, 'ER',  9., 500.,  353,  304, 39.27064444)\n",
      " (10000, 'ER', 32.,  50., 1820,  516, 56.899225  )\n",
      " (10000, 'ER', 32., 100., 1689,  646, 52.80539375)\n",
      " (10000, 'ER', 32., 150., 1603,  733, 50.11791563)\n",
      " (10000, 'ER', 32., 200., 1536,  800, 48.00372813)\n",
      " (10000, 'ER', 32., 250., 1481,  856, 46.28837813)\n",
      " (10000, 'ER', 32., 300., 1434,  902, 44.83642812)\n",
      " (10000, 'ER', 32., 350., 1393,  943, 43.53169688)\n",
      " (10000, 'ER', 32., 400., 1357,  979, 42.43155625)\n",
      " (10000, 'ER', 32., 450., 1326, 1011, 41.43995313)\n",
      " (10000, 'ER', 32., 500., 1295, 1041, 40.49555625)\n",
      " (10000, 'ER', 41.,  50., 2355,  638, 57.46319512)\n",
      " (10000, 'ER', 41., 100., 2175,  818, 53.05709756)\n",
      " (10000, 'ER', 41., 150., 2050,  944, 50.00481951)\n",
      " (10000, 'ER', 41., 200., 1950, 1042, 47.5820561 )\n",
      " (10000, 'ER', 41., 250., 1868, 1125, 45.58292195)\n",
      " (10000, 'ER', 41., 300., 1796, 1197, 43.8263878 )\n",
      " (10000, 'ER', 41., 350., 1734, 1260, 42.29961707)\n",
      " (10000, 'ER', 41., 400., 1682, 1311, 41.03874634)\n",
      " (10000, 'ER', 41., 450., 1632, 1361, 39.8201561 )\n",
      " (10000, 'ER', 41., 500., 1588, 1405, 38.75226585)]\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function to summarize the NEST data generated\n",
    "# FUNCTION:\n",
    "#   - check wheter for every entry in the 'run_list' there is an output .npy file\n",
    "#   - load the corresponding file and generate a tuple containing the summarizing quantities (e.g. mean number of photons, mean number of electrons)\n",
    "#   - generate an output np.array containing all the relevant data\n",
    "# INPUT:\n",
    "#   - run_string (string): name of the run\n",
    "#   - pathstring (string): path where the data is taken from and into which the array will be saved\n",
    "#   - run_list (list): run_list of the run (based on this list the NEST output will be searched)\n",
    "# OUTPUT:\n",
    "#   - summary_array (np.array): np.array containing the summarized NEST data\n",
    "#   or\n",
    "#   - 0 (int): if the summary array could not be generated\n",
    "def summarize_np_arrays(run_string, pathstring, run_list):\n",
    "    directory = os.fsencode(pathstring +run_string)\n",
    "    #run_list_string_list = generate_run_list_string_list(run_list)\n",
    "    counter_should_be = len(run_list)\n",
    "    counter_is = 0\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"Summarizing the NEST Output\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    ### evaluating the NEST output files and write the summary into tuple list\n",
    "    # defining the dtype\n",
    "    store_dtype = np.dtype([\n",
    "        (\"number_of_events\", np.uint16),\n",
    "        (\"interaction_type\", np.unicode_, 16),\n",
    "        (\"energy_deposition\", np.float64),\n",
    "        (\"field_strength\", np.float64),\n",
    "        (\"mean_number_of_photons\", np.uint16),\n",
    "        (\"mean_number_of_electrons\", np.uint16),\n",
    "        (\"photon_yield\", np.float64),\n",
    "    ])\n",
    "    sum_tuple_list = []\n",
    "    # scanning the run folder for NEST output stored in .npy files\n",
    "    print(\"Scanning for .npy files:\")\n",
    "    for i in run_list:\n",
    "        jfk = generate_string_from_run_list_entry(i) +\".npy\"\n",
    "        if os.path.isfile(pathstring +run_string +\"/\" +jfk):\n",
    "            print(\"{} ---> file found\".format(i))\n",
    "            np_file = np.load(pathstring +run_string +\"/\" +jfk)\n",
    "            sum_tuple = (i[0], np_file[\"interaction_type\"][0], np_file[\"energy_deposition\"][0], np_file[\"field_strength\"][0], np.mean(np_file[\"number_of_photons\"]), np.mean(np_file[\"number_of_electrons\"]), np.mean(np_file[\"number_of_photons\"])/np_file[\"energy_deposition\"][0])\n",
    "            sum_tuple_list.append(sum_tuple)\n",
    "            counter_is = counter_is +1\n",
    "        else:\n",
    "            print(\"{}\".format(i))\n",
    "#    for filestring in run_list_string_list:\n",
    "#        if os.path.isfile(pathstring +run_string +\"/\" +filestring):\n",
    "#            print(\"File found: {}\".format(filestring))\n",
    "#        else:\n",
    "#            print(\"The file {} could not be found.\".format(filestring))\n",
    "    print(\"Finished scanning for .npy files:\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    ### writing the summarized stuff into a np.array\n",
    "    # printing whether everything worked out\n",
    "    if counter_is == counter_should_be:\n",
    "        print(\"For all runs in 'run_list' a corresponding NEST output .npy file was found.\")\n",
    "    else:\n",
    "        print(\"Not for all of the runs a corresponding output could be found.\")\n",
    "        print(\"Please compare the 'run_list' and the 'run_list_string_list' to find out what files are missing.\")\n",
    "    # generating the summary np.array\n",
    "    try:\n",
    "        summary_array = np.array(sum_tuple_list, store_dtype)\n",
    "        np.save(pathstring +run_string +\"/\" +run_string +\"__SUMMARY\" +\".npy\", summary_array)\n",
    "        print(\"{} saved:\".format(run_string +\"__SUMMARY\" +\".npy\"))\n",
    "        print(summary_array.dtype.names)\n",
    "        print(summary_array)\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        return summary_array\n",
    "    except:\n",
    "        print(\"The summary np.array could not be generated.\")\n",
    "        print(\"np.array not saved.\")\n",
    "        print(\"-----------------------------------------------------\\n\\n\")\n",
    "        return 0        \n",
    "            \n",
    "run_res = summarize_np_arrays(run_string=run_name, pathstring=output_string, run_list=run_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 733  800  856  902  943  979 1011 1041]\n"
     ]
    }
   ],
   "source": [
    "# for reference\n",
    "#store_dtype = np.dtype([\n",
    "#    (\"number_of_events\", np.uint16),\n",
    "#    (\"interaction_type\", np.unicode_, 16),\n",
    "#    (\"energy_deposition\", np.float32),\n",
    "#    (\"field_strength\", np.float32),\n",
    "#    (\"mean_number_of_photons\", np.uint16),\n",
    "#    (\"mean_number_of_electrons\", np.uint16),\n",
    "#    (\"photon_yield\", np.float32),\n",
    "#])\n",
    "\n",
    "\n",
    "#  EXAMPLE\n",
    "test_array = np.load(\"./OUTPUT_Generating_NEST_Data/20191107__ER_gnampfinos_for_Daniel_and_Mariana_2/20191107__ER_gnampfinos_for_Daniel_and_Mariana_2__SUMMARY.npy\")\n",
    "#print(test_array[\"photon_yield\"][(run_res[\"energy_deposition\"] == 32) & (run_res[\"field_strength\"] == 500)])\n",
    "print(test_array[\"mean_number_of_electrons\"][(test_array[\"energy_deposition\"] == 32) & (test_array[\"field_strength\"] > 100)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
